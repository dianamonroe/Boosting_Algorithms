{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting Algorythm Project Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>Age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112.0</td>\n",
       "      <td>28.2</td>\n",
       "      <td>82.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139.0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>46.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134.0</td>\n",
       "      <td>46.2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Glucose   BMI  BloodPressure   Age  has_diabetes\n",
       "0     84.0   0.0            0.0  21.0             0\n",
       "1    112.0  28.2           82.0  50.0             1\n",
       "2    139.0  28.7           46.0  22.0             0\n",
       "3    161.0  21.9           50.0  65.0             0\n",
       "4    134.0  46.2           80.0  46.0             1"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A) Testing out performance using previous best performing -Optimized- Random Forest model \n",
    "# Recovering previously processed data without feature selection \n",
    "clean_train_raw = pd.read_csv('/workspaces/Boosting_Project_Tutorial_DianaM/data/processed/clean_train.csv')\n",
    "clean_test_raw = pd.read_csv('/workspaces/Boosting_Project_Tutorial_DianaM/data/processed/clean_test.csv')\n",
    "\n",
    "clean_train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>Age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98</td>\n",
       "      <td>34.0</td>\n",
       "      <td>58</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112</td>\n",
       "      <td>35.7</td>\n",
       "      <td>75</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108</td>\n",
       "      <td>30.8</td>\n",
       "      <td>64</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>24.6</td>\n",
       "      <td>80</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136</td>\n",
       "      <td>29.9</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Glucose   BMI  BloodPressure  Age  has_diabetes\n",
       "0       98  34.0             58   43             0\n",
       "1      112  35.7             75   21             0\n",
       "2      108  30.8             64   21             0\n",
       "3      107  24.6             80   34             0\n",
       "4      136  29.9             90   50             0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112.0</td>\n",
       "      <td>28.2</td>\n",
       "      <td>82.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139.0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>46.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134.0</td>\n",
       "      <td>46.2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Glucose   BMI  BloodPressure   Age\n",
       "0     84.0   0.0            0.0  21.0\n",
       "1    112.0  28.2           82.0  50.0\n",
       "2    139.0  28.7           46.0  22.0\n",
       "3    161.0  21.9           50.0  65.0\n",
       "4    134.0  46.2           80.0  46.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A) Testing out performance using previous best performing -Optimized- Random Forest model \n",
    "# Resetting X_train and X_test Recovering without feature selection \n",
    "\n",
    "X_train = clean_train_raw.drop(columns = \"has_diabetes\")\n",
    "X_test = clean_test_raw.drop(columns = \"has_diabetes\")\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "y_test = pd.read_csv('y_test.csv')\n",
    "\n",
    "\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98</td>\n",
       "      <td>34.0</td>\n",
       "      <td>58</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112</td>\n",
       "      <td>35.7</td>\n",
       "      <td>75</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108</td>\n",
       "      <td>30.8</td>\n",
       "      <td>64</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>24.6</td>\n",
       "      <td>80</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136</td>\n",
       "      <td>29.9</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Glucose   BMI  BloodPressure  Age\n",
       "0       98  34.0             58   43\n",
       "1      112  35.7             75   21\n",
       "2      108  30.8             64   21\n",
       "3      107  24.6             80   34\n",
       "4      136  29.9             90   50"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Random Forest Accuracy (test): 0.7727272727272727\n",
      "\n",
      " Random Forest Accuracy (train): 0.8436482084690554\n",
      "\n",
      " \n",
      " Random Forest f1_score (test): 0.7727272727272727\n",
      "\n",
      " Random Forest f1_score (train): 0.8436482084690554\n",
      "\n",
      " \n",
      " Random Forest precision (test): 0.7727272727272727\n",
      "\n",
      " Random Forest precision (train): 0.8436482084690554\n",
      "\n",
      " \n",
      " Random Forest recall (test): 0.7727272727272727\n",
      "\n",
      " Random Forest recall (train): 0.8436482084690554\n"
     ]
    }
   ],
   "source": [
    "# A) Testing out performance using previous best performing -Optimized- Random Forest model \n",
    "# Setting the best random forest model as the boosting input\n",
    "\n",
    "random_forest_model = RandomForestClassifier(n_estimators = 1000, max_depth = 5, min_samples_split = 5,\n",
    "                                             min_samples_leaf = 2, random_state = 42)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions for test set\n",
    "y_pred_test = random_forest_model.predict(X_test)\n",
    "\n",
    "# Get predictions for training set to evaluate training performance\n",
    "y_pred_train = random_forest_model.predict(X_train) \n",
    " \n",
    "\n",
    "# Evaluation:\n",
    "\n",
    "print(f\"\\n \\n Random Forest Accuracy (test): {accuracy_score(y_test, y_pred_test)}\")\n",
    "print(f\"\\n Random Forest Accuracy (train): {accuracy_score(y_train, y_pred_train)}\") \n",
    "print(f\"\\n \\n Random Forest f1_score (test): {f1_score(y_test, y_pred_test, average='micro')}\")\n",
    "print(f\"\\n Random Forest f1_score (train): {f1_score(y_train, y_pred_train, average='micro')}\") \n",
    "print(f\"\\n \\n Random Forest precision (test): {precision_score(y_test, y_pred_test, average='micro')}\") \n",
    "print(f\"\\n Random Forest precision (train): {precision_score(y_train, y_pred_train, average='micro')}\") \n",
    "print(f\"\\n \\n Random Forest recall (test): {recall_score(y_test, y_pred_test, average='micro')}\")\n",
    "print(f\"\\n Random Forest recall (train): {recall_score(y_train, y_pred_train, average='micro')}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prev. Random Forest to XGBClassifier Accuracy (test): 0.7857142857142857\n",
      "Prev. Random Forest to XGBClassifier f1_score (test): 0.7857142857142857\n",
      "Prev. Random Forest to XGBClassifier precision (test): 0.7857142857142857\n",
      "Prev. Random Forest to XGBClassifier recall (test): 0.7857142857142857\n",
      "\n",
      "Prev. Random Forest to XGBClassifier Accuracy (train): 0.8355048859934854\n",
      "Prev. Random Forest to XGBClassifier f1_score (train): 0.8355048859934854\n",
      "Prev. Random Forest to XGBClassifier precision (train): 0.8355048859934854\n",
      "Prev. Random Forest to XGBClassifier recall (train): 0.8355048859934854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [13:24:21] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# A) Applying the boosting algorythm to the best performing previous random forest \n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Convert predictions of random forest algorythm to DMatrix format for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, base_margin=random_forest_model.predict_proba(X_train)[:,1])\n",
    "dtest = xgb.DMatrix(X_test, label=y_test, base_margin=random_forest_model.predict_proba(X_test)[:,1])\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # For binary classification\n",
    "    'eval_metric': 'logloss', \n",
    "    'learning_rate': 0.03,\n",
    "    'max_depth': 3,  \n",
    "    'n_estimators': 500  \n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "prev_xgb_model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Make predictions on the test set\n",
    "prev_y_pred_xgb_test = prev_xgb_model.predict(dtest)\n",
    "y_pred_xgb_binary_test = [round(value) for value in prev_y_pred_xgb_test]\n",
    "\n",
    "# Make predictions on the train set\n",
    "prev_y_pred_xgb_train = prev_xgb_model.predict(dtrain)\n",
    "y_pred_xgb_binary_train = [round(value) for value in prev_y_pred_xgb_train]\n",
    "\n",
    "\n",
    "\n",
    "# Evaluation on test set\n",
    "print(f\"\\nPrev. Random Forest to XGBClassifier Accuracy (test): {accuracy_score(y_test, y_pred_xgb_binary_test)}\")\n",
    "print(f\"Prev. Random Forest to XGBClassifier f1_score (test): {f1_score(y_test, y_pred_xgb_binary_test, average='micro')}\")\n",
    "print(f\"Prev. Random Forest to XGBClassifier precision (test): {precision_score(y_test, y_pred_xgb_binary_test, average='micro')}\")\n",
    "print(f\"Prev. Random Forest to XGBClassifier recall (test): {recall_score(y_test, y_pred_xgb_binary_test, average='micro')}\")\n",
    "\n",
    "# Evaluation on train set\n",
    "print(f\"\\nPrev. Random Forest to XGBClassifier Accuracy (train): {accuracy_score(y_train, y_pred_xgb_binary_train)}\")\n",
    "print(f\"Prev. Random Forest to XGBClassifier f1_score (train): {f1_score(y_train, y_pred_xgb_binary_train, average='micro')}\")\n",
    "print(f\"Prev. Random Forest to XGBClassifier precision (train): {precision_score(y_train, y_pred_xgb_binary_train, average='micro')}\")\n",
    "print(f\"Prev. Random Forest to XGBClassifier recall (train): {recall_score(y_train, y_pred_xgb_binary_train, average='micro')}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(prev_xgb_model, open(\"../models/prev_random_forest_boosting_classifier_nestimators-500_learnrate-0.03_42.sav\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B) Applying the boost algorythm from scracth\n",
    "# recovering the data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"../data/processed/clean_train.csv\")\n",
    "test_data = pd.read_csv(\"../data/processed/clean_test.csv\")\n",
    "\n",
    "X_train = train_data.drop([\"has_diabetes\"], axis = 1)\n",
    "y_train = train_data[\"has_diabetes\"]\n",
    "X_test = test_data.drop([\"has_diabetes\"], axis = 1)\n",
    "y_test = test_data[\"has_diabetes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " XGBClassifier Accuracy (test): 0.7662337662337663\n",
      "\n",
      " XGBClassifier Accuracy (train): 0.7850162866449512\n",
      "\n",
      " \n",
      " XGBClassifier f1_score (test): 0.7662337662337663\n",
      "\n",
      " XGBClassifier f1_score (train): 0.7850162866449512\n",
      "\n",
      " \n",
      " RXGBClassifier precision (test): 0.7662337662337663\n",
      "\n",
      " XGBClassifier precision (train): 0.7850162866449512\n",
      "\n",
      " \n",
      " XGBClassifier recall (test): 0.7662337662337663\n",
      "\n",
      " XGBClassifier recall (train): 0.7850162866449512\n"
     ]
    }
   ],
   "source": [
    "# B) Applying the boost algorythm from scratch\n",
    "# Runingn the Boosting algorythm from scracth\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "scratch_XGBClassifier_model = XGBClassifier(n_estimators = 600, learning_rate = 0.001, random_state = 42)\n",
    "scratch_XGBClassifier_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Get predictions for test set\n",
    "y_pred_test_XGBClassifier = scratch_XGBClassifier_model.predict(X_test)\n",
    "\n",
    "# Get predictions for training set to evaluate training performance\n",
    "y_pred_train_XGBClassifier = scratch_XGBClassifier_model.predict(X_train)  \n",
    "\n",
    "\n",
    "# Evaluation:\n",
    "\n",
    "print(f\"\\n \\n XGBClassifier Accuracy (test): {accuracy_score(y_test, y_pred_test_XGBClassifier)}\")\n",
    "print(f\"\\n XGBClassifier Accuracy (train): {accuracy_score(y_train, y_pred_train_XGBClassifier)}\") \n",
    "print(f\"\\n \\n XGBClassifier f1_score (test): {f1_score(y_test, y_pred_test_XGBClassifier, average='micro')}\")\n",
    "print(f\"\\n XGBClassifier f1_score (train): {f1_score(y_train, y_pred_train_XGBClassifier, average='micro')}\") \n",
    "print(f\"\\n \\n RXGBClassifier precision (test): {precision_score(y_test, y_pred_test_XGBClassifier, average='micro')}\") \n",
    "print(f\"\\n XGBClassifier precision (train): {precision_score(y_train, y_pred_train_XGBClassifier, average='micro')}\") \n",
    "print(f\"\\n \\n XGBClassifier recall (test): {recall_score(y_test, y_pred_test_XGBClassifier, average='micro')}\")\n",
    "print(f\"\\n XGBClassifier recall (train): {recall_score(y_train, y_pred_train_XGBClassifier, average='micro')}\")\n",
    "\n",
    "from pickle import dump\n",
    "\n",
    "dump(scratch_XGBClassifier_model, open(\"../models/scractch_boosting_classifier_nestimators-600_learnrate-0.001_42.sav\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Optimized Decision Tree (test): 0.7142857142857143\n",
      "\n",
      " Optimized Decision Tree Accuracy (train): 0.8078175895765473\n",
      "\n",
      " Optimized Decision Tree Accuracy overfitting: 0.09353187529083296\n",
      "\n",
      " \n",
      " Optimized Decision Tree f1_score (test): 0.7142857142857143\n",
      "\n",
      " Optimized Decision Tree f1_score (train): 0.8078175895765473\n",
      "\n",
      " Optimized Decision Tree f1_score overfitting: 0.10234442452015668\n",
      "\n",
      " \n",
      " Optimized Decision Tree Precision (test): 0.7142857142857143\n",
      "\n",
      " Optimized Decision Tree Precision (train): 0.8078175895765473\n",
      "\n",
      " Optimized Decision Tree Precision overfitting: 0.10178049428647351\n",
      "\n",
      " \n",
      " Optimized Decision Tree Recall (test): 0.7142857142857143\n",
      "\n",
      " Optimized Decision Tree Recall (train): 0.8078175895765473\n",
      "\n",
      " Optimized Decision Tree Recall overfitting: 0.09961587708066577\n"
     ]
    }
   ],
   "source": [
    "# RUNNING ALL THE PREVIOUS ALOGRYTHMS FOR FINAL COMPARSION\n",
    "\n",
    "# Traing again the Decision Tree just with the selected features:\n",
    "\n",
    "dt_model = DecisionTreeClassifier(criterion =  \"entropy\", max_depth = 5, min_samples_leaf = 4, min_samples_split = 2, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Model prediction (test)\n",
    "dt_y_pred_2_test = dt_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Model prediction (train) \n",
    "dt_y_pred_2_train = dt_model.predict(X_train)\n",
    "\n",
    "\n",
    "print(f\"\\n \\n Optimized Decision Tree (test): {accuracy_score(y_test, dt_y_pred_2_test)}\")\n",
    "print(f\"\\n Optimized Decision Tree Accuracy (train): {accuracy_score(y_train, dt_y_pred_2_train)}\") \n",
    "print(f\"\\n Optimized Decision Tree Accuracy overfitting: {accuracy_score(y_train, dt_y_pred_2_train)-accuracy_score(y_test, dt_y_pred_2_test)}\") \n",
    "print(f\"\\n \\n Optimized Decision Tree f1_score (test): {f1_score(y_test, dt_y_pred_2_test, average='micro')}\") \n",
    "print(f\"\\n Optimized Decision Tree f1_score (train): {f1_score(y_train, dt_y_pred_2_train, average='micro')}\") \n",
    "print(f\"\\n Optimized Decision Tree f1_score overfitting: {f1_score(y_train, dt_y_pred_2_train)-f1_score(y_test, dt_y_pred_2_test)}\") \n",
    "print(f\"\\n \\n Optimized Decision Tree Precision (test): {precision_score(y_test, dt_y_pred_2_test, average='micro')}\") \n",
    "print(f\"\\n Optimized Decision Tree Precision (train): {precision_score(y_train, dt_y_pred_2_train, average='micro')}\") \n",
    "print(f\"\\n Optimized Decision Tree Precision overfitting: {precision_score(y_train, dt_y_pred_2_train)-precision_score(y_test, dt_y_pred_2_test)}\") \n",
    "print(f\"\\n \\n Optimized Decision Tree Recall (test): {recall_score(y_test, dt_y_pred_2_test, average='micro')}\") \n",
    "print(f\"\\n Optimized Decision Tree Recall (train): {recall_score(y_train, dt_y_pred_2_train, average='micro')}\") \n",
    "print(f\"\\n Optimized Decision Tree Recall overfitting: {recall_score(y_train, dt_y_pred_2_train)-recall_score(y_test, dt_y_pred_2_test)}\") \n",
    "\n",
    "from pickle import dump\n",
    "\n",
    "dump(dt_model , open(\"grid_search_optimized_decision_tree_all_features_42.sav\", \"wb\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " Optimized Random Forest Accuracy (test): 0.7727272727272727\n",
      "\n",
      " Optimized Random Forest Accuracy (train): 0.8403908794788274\n",
      "\n",
      " \n",
      " Optimized Random Forest f1_score (test): 0.7727272727272727\n",
      "\n",
      " Optimized Random Forest f1_score (train): 0.8403908794788274\n",
      "\n",
      " \n",
      " Optimized Random Forest precision (test): 0.7727272727272727\n",
      "\n",
      " Optimized Random Forest precision (train): 0.8403908794788274\n",
      "\n",
      " \n",
      " Optimized Random Forest recall (test): 0.7727272727272727\n",
      "\n",
      " Optimized Random Forest recall (train): 0.8403908794788274\n"
     ]
    }
   ],
   "source": [
    "# 11) Optimized Random Forest Model -  Manually\n",
    "\n",
    "\n",
    "optimized_random_forest_model = RandomForestClassifier(n_estimators = 500, max_depth = 5, min_samples_split = 5,\n",
    "                                             min_samples_leaf = 2, random_state = 42)\n",
    "optimized_random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Get predictions for test set\n",
    "random_forest_model_y_pred_test = optimized_random_forest_model.predict(X_test)\n",
    "\n",
    "# Get predictions for training set to evaluate training performance\n",
    "random_forest_model_y_pred_train = optimized_random_forest_model.predict(X_train)  \n",
    "\n",
    "# Evaluation:\n",
    "\n",
    "print(f\"\\n \\n Optimized Random Forest Accuracy (test): {accuracy_score(y_test, random_forest_model_y_pred_test)}\")\n",
    "print(f\"\\n Optimized Random Forest Accuracy (train): {accuracy_score(y_train, random_forest_model_y_pred_train)}\") \n",
    "print(f\"\\n \\n Optimized Random Forest f1_score (test): {f1_score(y_test, random_forest_model_y_pred_test, average='micro')}\") \n",
    "print(f\"\\n Optimized Random Forest f1_score (train): {f1_score(y_train, random_forest_model_y_pred_train, average='micro')}\") \n",
    "print(f\"\\n \\n Optimized Random Forest precision (test): {precision_score(y_test, random_forest_model_y_pred_test, average='micro')}\")\n",
    "print(f\"\\n Optimized Random Forest precision (train): {precision_score(y_train, random_forest_model_y_pred_train, average='micro')}\") \n",
    "print(f\"\\n \\n Optimized Random Forest recall (test): {recall_score(y_test, random_forest_model_y_pred_test, average='micro')}\") \n",
    "print(f\"\\n Optimized Random Forest recall (train): {recall_score(y_train, random_forest_model_y_pred_train, average='micro')}\")\n",
    "\n",
    "from pickle import dump\n",
    "\n",
    "dump(optimized_random_forest_model , open(\"optimized_random_forest_model_1000estimators_max_depth5_min_samples_split5_min_samples_leaf2_42.sav\", \"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report - Optimized Decision Tree:\n",
      "              train_precision  train_recall  train_f1-score  train_support  \\\n",
      "accuracy             0.807818      0.807818        0.807818       0.807818   \n",
      "macro avg            0.792345      0.816550        0.797902     614.000000   \n",
      "weighted avg         0.826974      0.807818        0.811609     614.000000   \n",
      "\n",
      "              test_precision  test_recall  test_f1-score  test_support  \\\n",
      "accuracy            0.714286     0.714286       0.714286      0.714286   \n",
      "macro avg           0.704395     0.721212       0.704518    154.000000   \n",
      "weighted avg        0.740661     0.714286       0.719867    154.000000   \n",
      "\n",
      "              overfitting  \n",
      "accuracy         0.093532  \n",
      "macro avg        0.093385  \n",
      "weighted avg     0.091741  \n",
      "\n",
      "Classification Report - Optimized Random Forest:\n",
      "              train_precision  train_recall  train_f1-score  train_support  \\\n",
      "accuracy             0.840391      0.840391        0.840391       0.840391   \n",
      "macro avg            0.831144      0.809572        0.818321     614.000000   \n",
      "weighted avg         0.838387      0.840391        0.837710     614.000000   \n",
      "\n",
      "              test_precision  test_recall  test_f1-score  test_support  \\\n",
      "accuracy            0.772727     0.772727       0.772727      0.772727   \n",
      "macro avg           0.752593     0.750505       0.751510    154.000000   \n",
      "weighted avg        0.771852     0.772727       0.772256    154.000000   \n",
      "\n",
      "              overfitting  \n",
      "accuracy         0.067664  \n",
      "macro avg        0.066811  \n",
      "weighted avg     0.065454  \n",
      "\n",
      "Classification Report - XGBClassifier:\n",
      "              train_precision  train_recall  train_f1-score  train_support  \\\n",
      "accuracy             0.785016      0.785016        0.785016       0.785016   \n",
      "macro avg            0.831587      0.701146        0.717599     614.000000   \n",
      "weighted avg         0.810336      0.785016        0.759847     614.000000   \n",
      "\n",
      "              test_precision  test_recall  test_f1-score  test_support  \\\n",
      "accuracy            0.766234     0.766234       0.766234      0.766234   \n",
      "macro avg           0.799942     0.688889       0.700842    154.000000   \n",
      "weighted avg        0.785110     0.766234       0.740804    154.000000   \n",
      "\n",
      "              overfitting  \n",
      "accuracy         0.018783  \n",
      "macro avg        0.016757  \n",
      "weighted avg     0.019044  \n",
      "\n",
      "Classification Report - Previous XGBoost Model:\n",
      "              train_precision  train_recall  train_f1-score  train_support  \\\n",
      "accuracy             0.835505      0.835505        0.835505       0.835505   \n",
      "macro avg            0.825771      0.803631        0.812517     614.000000   \n",
      "weighted avg         0.833333      0.835505        0.832618     614.000000   \n",
      "\n",
      "              test_precision  test_recall  test_f1-score  test_support  \\\n",
      "accuracy            0.785714     0.785714       0.785714      0.785714   \n",
      "macro avg           0.766852     0.764646       0.765709    154.000000   \n",
      "weighted avg        0.784894     0.785714       0.785270    154.000000   \n",
      "\n",
      "              overfitting  \n",
      "accuracy         0.049791  \n",
      "macro avg        0.046808  \n",
      "weighted avg     0.047348  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "def create_classification_report_df(y_true_train, y_pred_train, y_true_test, y_pred_test, target_names):\n",
    "    \"\"\"Creates a DataFrame for the classification report with overfitting.\"\"\"\n",
    "\n",
    "    report_train = classification_report(y_true_train, y_pred_train, target_names=target_names, output_dict=True)\n",
    "    report_test = classification_report(y_true_test, y_pred_test, target_names=target_names, output_dict=True)\n",
    "\n",
    "    df_report_train = pd.DataFrame(report_train).transpose()\n",
    "    df_report_test = pd.DataFrame(report_test).transpose()\n",
    "\n",
    "    # Rename columns to differentiate between train and test\n",
    "    df_report_train = df_report_train.add_prefix('train_')\n",
    "    df_report_test = df_report_test.add_prefix('test_')\n",
    "\n",
    "    # Concatenate train and test DataFrames\n",
    "    df_report = pd.concat([df_report_train, df_report_test], axis=1)\n",
    "\n",
    "    # Add overfitting column (train - test) for f1-score\n",
    "    df_report['overfitting'] = df_report['train_f1-score'] - df_report['test_f1-score']\n",
    "\n",
    "    # Remove rows for individual target values (0 and 1)\n",
    "    df_report = df_report[df_report.index.isin(['accuracy', 'macro avg', 'weighted avg'])]\n",
    "\n",
    "    return df_report\n",
    "\n",
    "# Assuming target names are 'no diabetes' and 'has diabetes'\n",
    "target_names = ['no diabetes', 'has diabetes']\n",
    "\n",
    "# Create DataFrames for each model\n",
    "report_df_optimized_dt = create_classification_report_df(y_train, dt_y_pred_2_train, y_test, dt_y_pred_2_test, target_names)\n",
    "report_df_optimized_rf = create_classification_report_df(y_train, random_forest_model_y_pred_train, y_test, random_forest_model_y_pred_test, target_names)\n",
    "report_df_xgb = create_classification_report_df(y_train, y_pred_train_XGBClassifier, y_test, y_pred_test_XGBClassifier, target_names)\n",
    "report_df_prev_xgb = create_classification_report_df(y_train, y_pred_xgb_binary_train, y_test, y_pred_xgb_binary_test, target_names) \n",
    "\n",
    "\n",
    "# Print the reports\n",
    "print(\"\\nClassification Report - Optimized Decision Tree:\")\n",
    "print(report_df_optimized_dt)\n",
    "\n",
    "print(\"\\nClassification Report - Optimized Random Forest:\")\n",
    "print(report_df_optimized_rf)\n",
    "\n",
    "print(\"\\nClassification Report - XGBClassifier:\")\n",
    "print(report_df_xgb)\n",
    "\n",
    "print(\"\\nClassification Report - Previous XGBoost Model:\")  \n",
    "print(report_df_prev_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-22 17:36:13.096 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.193 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /home/vscode/.local/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-12-22 17:36:13.193 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.194 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.195 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.196 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.196 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.197 Session state does not function when running a script without `streamlit run`\n",
      "2024-12-22 17:36:13.199 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.199 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.200 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.201 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.202 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.202 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.203 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.204 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.204 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.205 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.206 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.207 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.208 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.208 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.209 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.209 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.210 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.210 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.211 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.212 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.212 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.213 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.213 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.214 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-22 17:36:13.214 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "from pickle import load\n",
    "import streamlit as st\n",
    "import os\n",
    "\n",
    "model_file = \"optimized_random_forest_model_1000estimators_max_depth5_min_samples_split5_min_samples_leaf2_42.sav\"\n",
    "\n",
    "if not os.path.exists(model_file):\n",
    "    st.error(f\"The file of the model {model_file} is not found. Make sure it i in the system\")\n",
    "else:\n",
    "    # Load the saved model\n",
    "    with open(model_file, \"rb\") as file:\n",
    "        model = load(file)\n",
    "    # Class dictionary: \n",
    "    class_dict = {\n",
    "    0: \"Iris setosa\",\n",
    "    1: \"Iris versicolor\",\n",
    "    2: \"Iris virginica\"\n",
    "}\n",
    "\n",
    "    # Set application title\n",
    "    st.title(\"Iris - Model prediction\")\n",
    "\n",
    "    # Silders to collect user data entry\n",
    "\n",
    "    val1 = st.slider(\"Petal width\", min_value=0.1, max_value=2.5, step=0.1)\n",
    "    val2 = st.slider(\"Petal length\", min_value=1.0, max_value=7.0, step=0.1)\n",
    "    val3 = st.slider(\"Sepal width\", min_value=2.0, max_value=4.5, step=0.1)\n",
    "    val4 = st.slider(\"Sepal length\", min_value=4.0, max_value=8.0, step=0.1)\n",
    "\n",
    "    # Precict button\n",
    "    if st.button(\"Predict\"):\n",
    "        try: \n",
    "            prediction = model.predict([[val1, val2, val3, val4]])[0]\n",
    "            pred_class = class_dict.get(prediction, \"Unkown class\")\n",
    "            st.write(\"Prediction:\", pred_class)\n",
    "        except Exception as e:\n",
    "            st.error(f\"Failed predicting: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
